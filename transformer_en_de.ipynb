{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_en_de.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/specfazhou/coding_for_transformer/blob/main/transformer_en_de.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b98pF62canug",
        "outputId": "7bfdb323-dd54-4039-ee2a-5c844596b092"
      },
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=b1a4a2d520dc170d81f9edc760935e36ad3e0d7a8937182aec9ff783a39fd012\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1unijm78/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbDRWVB7QQ8I",
        "outputId": "a75e3ca0-d0cc-42af-a367-9b44b7aa62ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import IWSLT2017\n",
        "from typing import Iterable, List\n",
        "\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'de'\n",
        "\n",
        "new_IWSLT2017 = []\n",
        "i = 0\n",
        "for data in IWSLT2017(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)):\n",
        "  if i < 25000:\n",
        "    new_IWSLT2017.append(data)\n",
        "  else:\n",
        "    break\n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "# Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "# pip install -U spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "# python -m spacy download de_core_news_sm\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator\n",
        "    train_iter = new_IWSLT2017\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2017-01-trnmted.tgz: 329MB [00:02, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g36X4HQCRowg"
      },
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TVEjH_ZRrv5"
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGOvHn1DRuhl"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 256\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 64\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwfMn_wHSA2M"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo5cVkMtSHyX"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = new_IWSLT2017\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = IWSLT2017(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOlTasxRSRXn",
        "outputId": "3ff8f55a-a217-4369-f8e1-a5e359cda680"
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "train_losses_list = []\n",
        "valid_losses_list = []\n",
        "epoch_log = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "    train_losses_list.append(train_loss)\n",
        "    valid_losses_list.append(val_loss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 7.479, Val loss: 6.547, Epoch time = 140.569s\n",
            "Epoch: 2, Train loss: 6.190, Val loss: 6.243, Epoch time = 139.321s\n",
            "Epoch: 3, Train loss: 5.833, Val loss: 6.072, Epoch time = 139.447s\n",
            "Epoch: 4, Train loss: 5.556, Val loss: 5.918, Epoch time = 139.561s\n",
            "Epoch: 5, Train loss: 5.305, Val loss: 5.759, Epoch time = 139.620s\n",
            "Epoch: 6, Train loss: 5.091, Val loss: 5.664, Epoch time = 139.415s\n",
            "Epoch: 7, Train loss: 4.905, Val loss: 5.569, Epoch time = 139.469s\n",
            "Epoch: 8, Train loss: 4.735, Val loss: 5.477, Epoch time = 139.455s\n",
            "Epoch: 9, Train loss: 4.581, Val loss: 5.385, Epoch time = 139.120s\n",
            "Epoch: 10, Train loss: 4.439, Val loss: 5.312, Epoch time = 138.990s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO4BGzGJeHh7",
        "outputId": "533e5208-9346-4912-c71f-7f7d30486239"
      },
      "source": [
        "print(SRC_VOCAB_SIZE)\n",
        "print(TGT_VOCAB_SIZE)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22125\n",
            "37478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tXZE_sE-dB_",
        "outputId": "0d3cbd4b-3c32-4797-d608-f324fe85c8f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_losses_list)\n",
        "print(valid_losses_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.4792293038819455, 6.19048334570492, 5.833372542925198, 5.556289865537678, 5.3048241266509155, 5.090846871476039, 4.9047968296138835, 4.735461255168671, 4.580917790722664, 4.43863433096415]\n",
            "[6.547000408172607, 6.243416411536081, 6.07182993207659, 5.917664698192051, 5.75934978893825, 5.663524797984532, 5.5685604981013705, 5.4771813324519565, 5.385350704193115, 5.311921494347708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU1h6vdD_voh",
        "outputId": "8ca71524-df27-4887-80ce-2982717edb22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_log, train_losses_list)\n",
        "plt.plot(epoch_log, valid_losses_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f23887f2510>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS_5UZGrAtPY",
        "outputId": "add14b09-3be1-4df1-cb47-7d9769364be8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btN59hUZedGA"
      },
      "source": [
        "path = \"./drive/MyDrive/Colab Notebooks/transformer_en_de.ipynb\"\n",
        "torch.save(transformer.state_dict(), path)"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}